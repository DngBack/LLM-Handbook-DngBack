# LLM-Notes 🚀

A comprehensive collection of notes, insights, and experiments on Large Language Models (LLMs). This repository serves as a knowledge hub for everything related to LLMs, from theoretical foundations to practical deployment, fine-tuning strategies, and experimental implementations.

## Table Of Contents

- [📌 Introduction to LLMs](#introduction-to-llms): Basics, architectures, mathematical foundations, and key concepts.
- [🛠 LLM Fine-tuning with SFT](#llm-fine-tuning-with-sft): Techniques, frameworks, and best practices.
- [🎮 Deployment Strategies](#deployment-strategies): Serving LLMs using ONNX, FastAPI, Triton, and other tools.
- [💪 Optimization & Scaling](#optimization--scaling): Quantization, pruning, and performance tuning.
- **RLHF & Customization** – Reinforcement learning and aligning models for specific use cases.
- [🔄 RLHF & Customization](#rlhf--customization): Case studies, automation, and integration examples.
-
- [🌐 Real-world Applications](#real-world-applications): Scripts and test cases to evaluate different models and settings.

## 🚀 Why This Repo?

- Deeply explores the theory and mathematics behind LLMs.
- Provides practical test repositories to evaluate models.
- Offers a hands-on approach with experiments and deployment guides.
- Serves as a resource hub for engineers, researchers, and enthusiasts.

## 📌 Introduction to LLMs

- Basics, architectures, mathematical foundations, and key concepts.

## 📊 Mathematical Understanding

- Attention mechanisms, transformers, loss functions, optimization techniques.

## 🛠️ LLM Fine-tuning with SFT

- Techniques, frameworks, and best practices.

## 🎮 Deployment Strategies

- Serving LLMs using ONNX, FastAPI, Triton, and other tools.

## 💪 Optimization & Scaling

- Quantization, pruning, and performance tuning.

## 🔄 RLHF & Customization

- Reinforcement learning and aligning models for specific use cases.

## 🌐 Real-world Applications

- Case studies, automation, and integration examples.

## 🎧 LLM Test Repository

- Scripts and test cases to evaluate different models and settings.
